model_c50_cv <- train(Class~.,training,method='C5.0',trControl=ctrl)
summary(model_c50_cv)
grid <- expand.grid(.winnow,=c(TRUE,FALSE),.trials=c(1,5,10,15,20),.model='tree')
grid <- expand.grid(.winnow=c(TRUE,FALSE),.trials=c(1,5,10,15,20),.model='tree')
model_c50_cv_grid <- train(Class~.,training,method='c5.0',trControl=ctrl, tuneGrid=grid)
model_c50_cv_grid <- train(Class~.,training,method='C5.0',trControl=ctrl, tuneGrid=grid)
plot(model_c50_cv_grid)
model_c50_cv_grid_kappa <- train(Class~.,training,method='C5.0',trControl=ctrl, tuneGrid=grid,metric='Kappa')
plot(model_c50_cv_grid_kappa)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
ï¼Ÿpolynomial
?polynomial
??polynomial
# put your R code here inside the blocks
pred_a <- predict(glm_a,df.grid)
options(width = 100)  # set output width
# Section G?
# Group ??
# Members: YOUR NAMES HERE
UCBAdmissions.df <- as.data.frame(UCBAdmissions)
head(UCBAdmissions.df)
# put your R code here inside the blocks
library("tidyr")
data <- spread(UCBAdmissions.df, Admit, Freq)
data$Gender <- relevel(data$Gender, ref="Male")
summary(data)
data
# put your R code here inside the blocks
glm1 <- glm(cbind(Admitted, Rejected) ~ Gender, data, family = binomial())
summary(glm1)
# put your R code here inside the blocks
glm2 <- glm(cbind(Admitted, Rejected) ~ Gender+Dept, data, family = binomial())
summary(glm2)
# put your R code here inside the blocks
glm3 <- glm(cbind(Admitted, Rejected) ~ Gender*Dept, data, family = binomial())
summary(glm3)
library("ElemStatLearn")  # run install.packages("ElemStatLearn") if you haven't
# copy important ones out
x <- mixture.example$x
y <- mixture.example$y
prob <- mixture.example$prob
xnew <- mixture.example$xnew
px1 <- mixture.example$px1
px2 <- mixture.example$px2
# make dataframe for the training data (with x1, x2, and y)
df.training <- data.frame(x1=x[ , 1], x2=x[ , 2], y=y)
df.training$y <- as.factor(df.training$y)
# make dataframe for the "test" data (with xnew1, xnew2, and true prob, but not y!!)
df.grid <- data.frame(x1=xnew[ , 1], x2=xnew[ , 2])
df.grid$prob <- prob
# plot X and Y
library("ggplot2")
p0 <- ggplot() + geom_point(data=df.training, aes(x=x1, y=x2, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p.true <- p0 + stat_contour(data=df.grid, aes(x=x1, y=x2, z=prob), breaks=c(0.5))
p.true
# put your R code here inside the blocks
glm_a <- glm(y~x1+x2,family = binomial(),data=df.training)
summary(glm_a)
# put your R code here inside the blocks
pred_a <- predict(glm_a,df.grid)
head(pred_a)
library("ggplot2")
p0 <- ggplot() + geom_point(data=df.training, aes(x=x1, y=x2, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p0 + stat_contour(data=df.grid, aes(x=x1, y=x2, z=pred_a), breaks=c(0.5))
# put your R code here inside the blocks
glm_b <- glm(y~poly(x1,6)+poly(x2,6),df.training,family = binomial())
summary(glm_b)
pred_b <- predict(glm_b,df.grid)
p0 <- ggplot() + geom_point(data=df.training, aes(x=x1, y=x2, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p0 + stat_contour(data=df.grid, aes(x=x1, y=x2, z=pred_b), breaks=c(0.5))
library("mvtnorm")
set.seed(123)
centers <- c(sample(1:10, 5000, replace=TRUE),
sample(11:20, 5000, replace=TRUE))
means <- mixture.example$means
means <- means[centers, ]
x.test <- rmvnorm(10000, c(0, 0), 0.2 * diag(2))
x.test <- x.test + means
y.test <- c(rep(0, 5000), rep(1, 5000))
df.test <- data.frame(x1=x.test[, 1], x2=x.test[, 2], y=y.test)
# best possible misclassification rate
bayes.error <- sum(mixture.example$marginal * (prob * I(prob < 0.5) + (1-prob) * I(prob >= 0.5)))
## predict with various knn models
library("FNN")
ks <- c(1, 7, 100)
for (i in seq(along=ks)) {
mod.test  <- knn(x, x.test, y, k=ks[i], prob=TRUE)
prob <- attr(mod.test, "prob")
prob <- ifelse(mod.test == "1", prob, 1 - prob)
df.test[, paste0("prob.knn", ks[i])] <- prob
}
head(df.test)
# put your R code here inside the blocks
pred_a.test  <- predict(glm_a,df.test)
pred_a.test <- exp(pred_a.test)/(1+exp(pred_a.test))
df.test[, paste0("prob.glm_a")] <- pred_a.test
pred_b.test  <- predict(glm_b,df.test)
pred_b.test <- exp(pred_b.test)/(1+exp(pred_b.test))
df.test[, paste0("prob.glm_b")] <- pred_b.test
head(df.test)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
# put your R code here inside the blocks
plot(performance(pred1,"tpr","fpr"))
plot(performance(pred2,"tpr","fpr"),col="blue",add=TRUE)
plot(performance(pred3,"tpr","fpr"),col="red",add=TRUE)
plot(performance(pred4,"tpr","fpr"),col="purple",add=TRUE)
plot(performance(pred5,"tpr","fpr"),col="green",add=TRUE)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
ploy(bayes.error,add=TRUE)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
plot(bayes.error,add=TRUE)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
plot(bayes.error,add=TRUE,col="pink")
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
plot(performance(bayes.error,"err"),col="pink",add=TRUE)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
plot(bayes.error,col="pink",add=TRUE)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
options(width = 100)  # set output width
# Section G?
# Group ??
# Members: YOUR NAMES HERE
UCBAdmissions.df <- as.data.frame(UCBAdmissions)
head(UCBAdmissions.df)
# put your R code here inside the blocks
library("tidyr")
data <- spread(UCBAdmissions.df, Admit, Freq)
data$Gender <- relevel(data$Gender, ref="Male")
summary(data)
data
# put your R code here inside the blocks
glm1 <- glm(cbind(Admitted, Rejected) ~ Gender, data, family = binomial())
summary(glm1)
# put your R code here inside the blocks
glm2 <- glm(cbind(Admitted, Rejected) ~ Gender+Dept, data, family = binomial())
summary(glm2)
# put your R code here inside the blocks
glm3 <- glm(cbind(Admitted, Rejected) ~ Gender*Dept, data, family = binomial())
summary(glm3)
library("ElemStatLearn")  # run install.packages("ElemStatLearn") if you haven't
# copy important ones out
x <- mixture.example$x
y <- mixture.example$y
prob <- mixture.example$prob
xnew <- mixture.example$xnew
px1 <- mixture.example$px1
px2 <- mixture.example$px2
# make dataframe for the training data (with x1, x2, and y)
df.training <- data.frame(x1=x[ , 1], x2=x[ , 2], y=y)
df.training$y <- as.factor(df.training$y)
# make dataframe for the "test" data (with xnew1, xnew2, and true prob, but not y!!)
df.grid <- data.frame(x1=xnew[ , 1], x2=xnew[ , 2])
df.grid$prob <- prob
# plot X and Y
library("ggplot2")
p0 <- ggplot() + geom_point(data=df.training, aes(x=x1, y=x2, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p.true <- p0 + stat_contour(data=df.grid, aes(x=x1, y=x2, z=prob), breaks=c(0.5))
p.true
# put your R code here inside the blocks
glm_a <- glm(y~x1+x2,family = binomial(),data=df.training)
summary(glm_a)
# put your R code here inside the blocks
pred_a <- predict(glm_a,df.grid)
head(pred_a)
library("ggplot2")
p0 <- ggplot() + geom_point(data=df.training, aes(x=x1, y=x2, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p0 + stat_contour(data=df.grid, aes(x=x1, y=x2, z=pred_a), breaks=c(0.5))
# put your R code here inside the blocks
glm_b <- glm(y~poly(x1,6)+poly(x2,6),df.training,family = binomial())
summary(glm_b)
pred_b <- predict(glm_b,df.grid)
p0 <- ggplot() + geom_point(data=df.training, aes(x=x1, y=x2, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p0 + stat_contour(data=df.grid, aes(x=x1, y=x2, z=pred_b), breaks=c(0.5))
library("mvtnorm")
set.seed(123)
centers <- c(sample(1:10, 5000, replace=TRUE),
sample(11:20, 5000, replace=TRUE))
means <- mixture.example$means
means <- means[centers, ]
x.test <- rmvnorm(10000, c(0, 0), 0.2 * diag(2))
x.test <- x.test + means
y.test <- c(rep(0, 5000), rep(1, 5000))
df.test <- data.frame(x1=x.test[, 1], x2=x.test[, 2], y=y.test)
# best possible misclassification rate
bayes.error <- sum(mixture.example$marginal * (prob * I(prob < 0.5) + (1-prob) * I(prob >= 0.5)))
## predict with various knn models
library("FNN")
ks <- c(1, 7, 100)
for (i in seq(along=ks)) {
mod.test  <- knn(x, x.test, y, k=ks[i], prob=TRUE)
prob <- attr(mod.test, "prob")
prob <- ifelse(mod.test == "1", prob, 1 - prob)
df.test[, paste0("prob.knn", ks[i])] <- prob
}
head(df.test)
# put your R code here inside the blocks
pred_a.test  <- predict(glm_a,df.test)
pred_a.test <- exp(pred_a.test)/(1+exp(pred_a.test))
df.test[, paste0("prob.glm_a")] <- pred_a.test
pred_b.test  <- predict(glm_b,df.test)
pred_b.test <- exp(pred_b.test)/(1+exp(pred_b.test))
df.test[, paste0("prob.glm_b")] <- pred_b.test
head(df.test)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
# put your R code here inside the blocks
plot(performance(pred1,"tpr","fpr"))
plot(performance(pred2,"tpr","fpr"),col="blue",add=TRUE)
plot(performance(pred3,"tpr","fpr"),col="red",add=TRUE)
plot(performance(pred4,"tpr","fpr"),col="purple",add=TRUE)
plot(performance(pred5,"tpr","fpr"),col="green",add=TRUE)
# put your R code here inside the blocks
glm3 <- glm(cbind(Admitted, Rejected) ~ Gender*Dept, data, family = binomial())
summary(glm3)
data$prob <- predict(glm3, type="response")
# put your R code here inside the blocks
glm3 <- glm(cbind(Admitted, Rejected) ~ Gender*Dept, data, family = binomial())
summary(glm3)
data$prob <- predict(glm3, type="response")
head(data$prob)
# put your R code here inside the blocks
pred_a <- predict(glm_a,df.grid,type = responses)
# put your R code here inside the blocks
pred_a <- predict(glm_a,df.grid,type = response)
# put your R code here inside the blocks
pred_a <- predict(glm_a,df.grid,type = "response)
head(pred_a)
library("ggplot2")
# put your R code here inside the blocks
pred_a <- predict(glm_a,df.grid,type = 'response')
head(pred_a)
library("ggplot2")
p0 <- ggplot() + geom_point(data=df.training, aes(x=x1, y=x2, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p0 + stat_contour(data=df.grid, aes(x=x1, y=x2, z=pred_a), breaks=c(0.5))
# put your R code here inside the blocks
glm_b <- glm(y~poly(x1,6)+poly(x2,6),df.training,family = binomial())
summary(glm_b)
pred_b <- predict(glm_b,df.grid,type = 'response')
p0 <- ggplot() + geom_point(data=df.training, aes(x=x1, y=x2, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p0 + stat_contour(data=df.grid, aes(x=x1, y=x2, z=pred_b), breaks=c(0.5))
# put your R code here inside the blocks
pred_a.test  <- predict(glm_a,df.test,type = 'response')
df.test[, paste0("prob.glm_a")] <- pred_a.test
pred_b.test  <- predict(glm_b,df.test,type = 'response')
df.test[, paste0("prob.glm_b")] <- pred_b.test
head(df.test)
# put your R code here inside the blocks
glm_b <- glm(y~poly(x1,6,raw = TRUE)+poly(x2,6,raw=TRUE),df.training,family = binomial())
summary(glm_b)
pred_b <- predict(glm_b,df.grid,type = 'response')
p0 <- ggplot() + geom_point(data=df.training, aes(x=x1, y=x2, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p0 + stat_contour(data=df.grid, aes(x=x1, y=x2, z=pred_b), breaks=c(0.5))
library("mvtnorm")
set.seed(123)
centers <- c(sample(1:10, 5000, replace=TRUE),
sample(11:20, 5000, replace=TRUE))
means <- mixture.example$means
means <- means[centers, ]
x.test <- rmvnorm(10000, c(0, 0), 0.2 * diag(2))
x.test <- x.test + means
y.test <- c(rep(0, 5000), rep(1, 5000))
df.test <- data.frame(x1=x.test[, 1], x2=x.test[, 2], y=y.test)
# best possible misclassification rate
bayes.error <- sum(mixture.example$marginal * (prob * I(prob < 0.5) + (1-prob) * I(prob >= 0.5)))
## predict with various knn models
library("FNN")
ks <- c(1, 7, 100)
for (i in seq(along=ks)) {
mod.test  <- knn(x, x.test, y, k=ks[i], prob=TRUE)
prob <- attr(mod.test, "prob")
prob <- ifelse(mod.test == "1", prob, 1 - prob)
df.test[, paste0("prob.knn", ks[i])] <- prob
}
head(df.test)
# put your R code here inside the blocks
pred_a.test  <- predict(glm_a,df.test,type = 'response')
df.test[, paste0("prob.glm_a")] <- pred_a.test
pred_b.test  <- predict(glm_b,df.test,type = 'response')
df.test[, paste0("prob.glm_b")] <- pred_b.test
head(df.test)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
# put your R code here inside the blocks
plot(performance(pred1,"tpr","fpr"))
plot(performance(pred2,"tpr","fpr"),col="blue",add=TRUE)
plot(performance(pred3,"tpr","fpr"),col="red",add=TRUE)
plot(performance(pred4,"tpr","fpr"),col="purple",add=TRUE)
plot(performance(pred5,"tpr","fpr"),col="green",add=TRUE)
# put your R code here inside the blocks
par(pty = "s")
plot(performance(pred1,"tpr","fpr"))
plot(performance(pred2,"tpr","fpr"),col="blue",add=TRUE)
plot(performance(pred3,"tpr","fpr"),col="red",add=TRUE)
plot(performance(pred4,"tpr","fpr"),col="purple",add=TRUE)
plot(performance(pred5,"tpr","fpr"),col="green",add=TRUE)
# put your R code here inside the blocks
glm3 <- glm(cbind(Admitted, Rejected) ~ Gender*Dept, data, family = binomial())
summary(glm3)
data$prob <- predict(glm3, type="response")
head(data$prob)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
abline(bayes.error,col="pink")
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
abline(h=bayes.error,col="pink")
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
abline(h=bayes.error,col="pink",add=TRUE)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
abline(h=bayes.error,col="pink")
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
abline(h=bayes.error,col="yellow")
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
abline(h=bayes.error,col="orange")
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
abline(h=bayes.error,col="orange",size=15)
# put your R code here inside the blocks
library(ROCR)
pred1 <- prediction(df.test$prob.knn1,df.test$y)
pred2 <- prediction(df.test$prob.knn7,df.test$y)
pred3 <- prediction(df.test$prob.knn100,df.test$y)
pred4 <- prediction(df.test$prob.glm_a,df.test$y)
pred5 <- prediction(df.test$prob.glm_b,df.test$y)
plot(performance(pred1,"err"),ylim=c(0.2,0.5))
plot(performance(pred2,"err"),col="blue",add=TRUE)
plot(performance(pred3,"err"),col="red",add=TRUE)
plot(performance(pred4,"err"),col="purple",add=TRUE)
plot(performance(pred5,"err"),col="green",add=TRUE)
abline(h=bayes.error,col="orange")
