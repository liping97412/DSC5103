install.packages("ISLR")
library(ISLR)
?Default
head(Default)
summary(Default)
library("ISLR")
Default$default0 <- as.numeric(Default$default) - 1
View(Default)
View(Default)
lm0 <- lm(default0 ~ balance, data=Default)
summary(lm0)
plot(Default$balance, Default$default0)
abline(lm0, col="red", lwd=2)
glm1 <- glm(default ~ balance, data=Default, family=binomial())
summary(glm1)
str(glm1)
points(Default$balance, glm1$fitted.values, col="blue")
predict(glm1, newdata=data.frame(balance=c(1000, 2000)), type="response")
?predict.glm
glm2 <- glm(default ~ student, data=Default, family=binomial())
summary(glm2)
swirl()
library(swirl)
swirl()
test
summary(model_c50)
?predict.C5.0
predictions_class <- predict(model_c50,test)
table(predictions_class,test$class)
table(predictions_class,test$class)
table(predictions_class,test)
table(predictions_class,test$Class)
cm <- table(predictions_class,test$Class)
bye()
??tidyr
options(width = 100)  # set output width
UCBAdmissions.df <- as.data.frame(UCBAdmissions)
head(UCBAdmissions.df)
Titanic.df <- as.data.frame(Titanic)
Titanic.df
library("tidyr")
data <- spread(Titanic.df, Survived, Freq)
data$Age <- relevel(data$Age, ref="Adult")
summary(data)
data
View(UCBAdmissions.df)
View(UCBAdmissions.df)
# put your R code here inside the blocks
library("tidyr")
data <- spread(UCBAdmissions.df, Admit, Freq)
data$Gender <- relevel(data$Gender, ref="Male")
summary(data)
data
View(data)
View(data)
# put your R code here inside the blocks
glm1 <- glm(cbind(Admitted, Rejected) ~ Gender, data, family = binomial())
summary(glm1)
# put your R code here inside the blocks
glm2 <- glm(cbind(Admitted, Rejected) ~ Gender+Dept, data, family = binomial())
summary(glm2)
# put your R code here inside the blocks
glm3 <- glm(cbind(Admitted, Rejected) ~ Gender*Dept, data, family = binomial())
summary(glm3)
library("ElemStatLearn")  # run install.packages("ElemStatLearn") if you haven't
install.packages("ElemStatLearn")
library("ElemStatLearn")  # run install.packages("ElemStatLearn") if you haven't
# copy important ones out
x <- mixture.example$x
y <- mixture.example$y
prob <- mixture.example$prob
xnew <- mixture.example$xnew
px1 <- mixture.example$px1
px2 <- mixture.example$px2
# make dataframe for the training data (with x1, x2, and y)
df.training <- data.frame(x1=x[ , 1], x2=x[ , 2], y=y)
df.training$y <- as.factor(df.training$y)
# make dataframe for the "test" data (with xnew1, xnew2, and true prob, but not y!!)
df.grid <- data.frame(x1=xnew[ , 1], x2=xnew[ , 2])
df.grid$prob <- prob
# plot X and Y
library("ggplot2")
p0 <- ggplot() + geom_point(data=df.training, aes(x=x1, y=x2, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p.true <- p0 + stat_contour(data=df.grid, aes(x=x1, y=x2, z=prob), breaks=c(0.5))
p.true
# put your R code here inside the blocks
glm_a <- glm(y~x1+x2,df.training,family = binomial())
summary(glm_a)
# put your R code here inside the blocks
pred_a <- predict(glm_a,df.grid)
pred)_a
# put your R code here inside the blocks
pred_a <- predict(glm_a,df.grid)
pred_a
# put your R code here inside the blocks
pred_a <- predict(glm_a,df.grid)
pred_a <- predict(glm_a,df.grid)
library("ggplot2")
pred_a_plot <- ggplot() + geom_point(data=df.grid, aes(x=x1, y=x2, color=pre_a), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# put your R code here inside the blocks
pred_a <- predict(glm_a,df.grid)
library("ggplot2")
p0 <- ggplot() + geom_point(data=df.training, aes(x=x1, y=x2, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p0 + stat_contour(data=df.grid, aes(x=x1, y=x2, z=pred_a), breaks=c(0.5))
# put your R code here inside the blocks
glm_b <- glm(y~(x1)^6+(x2)^6,df.training,family = binomial())
summary(glm_b)
pred_b <- predict(glm_b,df.grid)
p0 <- ggplot() + geom_point(data=df.training, aes(x=(x1)^6, y=(x2)^6, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p0 + stat_contour(data=df.grid, aes(x=(x1)^6, y=(x2)^6, z=pred_b), breaks=c(0.5))
library("mvtnorm")
set.seed(123)
centers <- c(sample(1:10, 5000, replace=TRUE),
sample(11:20, 5000, replace=TRUE))
means <- mixture.example$means
means <- means[centers, ]
x.test <- rmvnorm(10000, c(0, 0), 0.2 * diag(2))
x.test <- x.test + means
y.test <- c(rep(0, 5000), rep(1, 5000))
df.test <- data.frame(x1=x.test[, 1], x2=x.test[, 2], y=y.test)
# best possible misclassification rate
bayes.error <- sum(mixture.example$marginal * (prob * I(prob < 0.5) + (1-prob) * I(prob >= 0.5)))
## predict with various knn models
library("FNN")
install.packages("FNN")
## predict with various knn models
library("FNN")
ks <- c(1, 7, 100)
for (i in seq(along=ks)) {
mod.test  <- knn(x, x.test, y, k=ks[i], prob=TRUE)
prob <- attr(mod.test, "prob")
prob <- ifelse(mod.test == "1", prob, 1 - prob)
df.test[, paste0("prob.knn", ks[i])] <- prob
}
head(df.test)
# put your R code here inside the blocks
prob <- attr(glm_a, "prob")
prob <- ifelse(glm_a) == "1", prob, 1 - prob)
# put your R code here inside the blocks
prob <- attr(glm_a, "prob")
prob <- ifelse(glm_a) == "1", prob, 1 - prob))
# put your R code here inside the blocks
prob <- attr(glm_a, "prob")
prob <- ifelse(glm_a == "1",prob, 1 - prob)
df.test[, paste0("prob.glma")] <- prob
# put your R code here inside the blocks
pred_a.test  <- predict(glm_a,x.test)
# put your R code here inside the blocks
x.test <- as.data.frame(x.test)
pred_a.test  <- predict(glm_a,x.test)
# put your R code here inside the blocks
glm_b <- glm(y~(x1)^6+(x2)^6,df.training,family = binomial())
summary(glm_b)
pred_b <- predict(glm_b,df.grid)
p0 <- ggplot() + geom_point(data=df.training, aes(x=(x1)^6, y=(x2)^6, color=y), size=4) + scale_color_manual(values=c("green", "red")) + theme_bw()
# add the true boundary into the plot
p0 + stat_contour(data=df.grid, aes(x=(x1)^6, y=(x2)^6, z=pred_b), breaks=c(0.5))
#############################
### load Credit Card Default data
#############################
library("ISLR")
?Default
head(Default)
summary(Default)
#############################
### try linear regression first
############################
# convert Y into numerical variable
Default$default0 <- as.numeric(Default$default) - 1
# default ~ balance
lm0 <- lm(default0 ~ balance, data=Default)
summary(lm0)
# visualize the fit
plot(Default$balance, Default$default0)
abline(lm0, col="red", lwd=2)
## Logistic regression 1: default ~ balance
# link="logit" is default and can be omitted
glm1 <- glm(default ~ balance, data=Default, family=binomial())
summary(glm1)
# inspect the output
str(glm1)
points(Default$balance, glm1$fitted.values, col="blue")
# prediction by glm1
predict(glm1, newdata=data.frame(balance=c(1000, 2000)), type="response")
# check prediction types
?predict.glm
## Logistic regression 2: default ~ student
glm2 <- glm(default ~ student, data=Default, family=binomial())
summary(glm2)
plot(Default$student, glm2$fitted.values)
## Logistic regression 3: default ~ .
glm3 <- glm(default ~ balance + income + student, data=Default, family=binomial())
summary(glm3)
## model selectin by AIC
library("MASS")
glm.best <- stepAIC(glm3, direction="both")
summary(glm.best)
## update()
glm4 <- update(glm3, . ~ . - income)
summary(glm4)
## other outputs
coef(glm4)  # coefficients
confint(glm4)  # 95% CI for the coefficients
fitted(glm4, type="response")  # fitted values
residuals(glm4, type="deviance")  # residuals
# plots as in linear regression
par(mfrow=c(2,2))
plot(glm4)
par(mfrow=c(1,1))
## categorical prediction (use fixed cutoff = 0.5)
Default$glm4.prob <- predict(glm4, type="response")
hist(Default$glm4.prob)
Default$glm4.pred <- (Default$glm4.prob > 0.5)
# confusion matrix
confusion.mat <- table(Default$glm4.pred, Default$default)
confusion.mat
TP <- confusion.mat[2, 2]
TN <- confusion.mat[1, 1]
FP <- confusion.mat[2, 1]
FN <- confusion.mat[1, 2]
recall <- TP / (TP + FN)
specificity <- TN / (FP + TN)
precision <- TP / (TP + FP)
accuracy <- (TP + TN) / nrow(Default)
## evaluate the measures with different cutoffs using the ROCR package
library("ROCR")
# STEP 1. construct a "prediction" object (consists of p_hat and Y)
glm4.pred <- prediction(Default$glm4.prob, Default$default)
str(glm4.pred)
# STEP 2. Select the measures using performance()
?performance
## single measure with respect to cutoff
# fpr, fnr, misclassification
glm4.fpr <- performance(glm4.pred, measure="fpr")
str(glm4.fpr)
glm4.fnr <- performance(glm4.pred, measure="fnr")
glm4.err <- performance(glm4.pred, measure="err")
# plot the measures in one figure
plot(glm4.fpr, col="red", ylab="")
plot(glm4.fnr, col="blue", add=TRUE)
plot(glm4.err, col="black", add=TRUE)
legend(x=0.55, y=0.5, legend=c("Error Rate", "False Positive Rate", "False Negative Rate"), lty=c(1, 1, 1), lwd=c(2, 2, 2), col=c("black", "red", "blue"))
glm4.acc <- performance(glm4.pred, measure="acc")
plot(glm4.acc)
# precision vs. cutoff
glm4.prec <- performance(glm4.pred, measure="prec")
plot(glm4.prec)
# ROC plot
glm4.ROC <- performance(glm4.pred, measure="tpr", x.measure="fpr")
plot(glm4.ROC)
abline(a=0, b=1, lty=2) # diagonal line
# AUC
glm4.auc <- performance(glm4.pred, "auc")
glm4.auc@y.values[[1]]
glm4.PR <- performance(glm4.pred, measure="prec", x.measure="rec")
plot(glm4.PR)
glm4.SS <- performance(glm4.pred, measure="sens", x.measure="spec")
plot(glm4.SS)
# Lift chart
glm4.lift <- performance(glm4.pred, measure="lift", x.measure="rpp")
plot(glm4.lift)
glm4.cost <- performance(glm4.pred, measure="cost", cost.fp=1, cost.fn=10)
plot(glm4.cost)
str(glm4.cost)
which.min(glm4.cost@y.values[[1]])
glm4.cost@x.values[[1]][which.min(glm4.cost@y.values[[1]])]
glm.probit <- glm(default ~ balance + student, data=Default, family=binomial(link="probit"))
summary(glm.probit)
?Titanic
str(Titanic)
Titanic  # it is a 4-dimensional table??
# visualize
library("graphics")
mosaicplot(Titanic, main = "Survival on the Titanic")
Titanic.df <- as.data.frame(Titanic)
Titanic.df
library("tidyr")
data <- spread(Titanic.df, Survived, Freq)
data$Age <- relevel(data$Age, ref="Adult")
summary(data)
data
glm1 <- glm(cbind(Yes, No) ~ Class + Sex + Age, data, family = binomial())
summary(glm1)
glm2 <- glm(cbind(Yes, No) ~ Class + Sex * Age, data, family = binomial())
summary(glm2)
glm3 <- glm(cbind(Yes, No) ~ Class * Sex * Age, data, family = binomial())
summary(glm3)
student.name <- "LI LIPING"  # put your name here
student.id <- 0320278  # put only the numeric digits of your NUS user id here
set.seed(student.id)
load("sales.rdata")  # load the data (make sure the .rdata file is in your working directory!)
load("sales.rdata")  # load the data (make sure the .rdata file is in your working directory!)
load("sales.rdata")  # load the data (make sure the .rdata file is in your working directory!)
load("sales.rdata")  # load the data (make sure the .rdata file is in your working directory!)
ls(all.names=T)  # list all the objects in the data file
summary(data.train)
summary(data.test)
View(data.train)
names(data.train)
formula <- as.formula(sales~weekend+holiday+prod_function+prod_regime+prod_listprice+discount+stockout)
formula_1a <- as.formula(sales~weekend+holiday+prod_id+prod_function+prod_regime+prod_listprice+discount+stockout)
formula_1b <- as.formula(sales~weekend+holiday+prod_function+prod_regime+prod_listprice+discount)
formula_1c <- as.formula(sales~weekend+holiday+prod_function+prod_listprice+discount)
data.train$log_sales <- log(1 + data.train$sales)
data.test$log_sales <- log(1 + data.test$sales)
formula <- as.formula(log_sales ~ weekend + holiday + prod_function + prod_regime + prod_listprice + discount + stockout)
model_2a <- lm()
model_2a <- lm(formula,data=data.train)
pred_2a <- predict(model_2a,data.test)
library("glmnetUtils")
model_lasso <- glmnet(formula,data.train)
plot(model_lasso, xvar="lambda", label=TRUE)
model_lasso <- glmnet(formula,data.train,alpha=1, use.model.frame=TRUE)
plot(model_lasso, xvar="lambda", label=TRUE)
# CV for optimal lambda
set.seed(456)
lasso.cv <- cv.glmnet(formula.,data.train,alpha=1, use.model.frame=TRUE)
lasso.cv <- cv.glmnet(formula,data.train,alpha=1, use.model.frame=TRUE)
plot(lasso.cv)
lasso.lam <- lasso.cv$lambda.min
log(lasso.lam)
lasso.lam2 <- lasso.cv$lambda.1se
log(lasso.lam2)
min(lasso.cv$cvm) + lasso.cv$cvsd[which.min(lasso.cv$cvm)]
points(log(lasso.lam2), min(lasso.cv$cvm) + lasso.cv$cvsd[which.min(lasso.cv$cvm)], cex=3)
plot(lasso.cv$glmnet.fit, xvar="lambda", label = TRUE)
abline(v=log(lasso.lam), lty=2)
abline(v=log(lasso.lam2), lty=2)
pred_lasso <- predict(lasso.cv, s=lasso.lam2, newdata=data.test, exact=TRUE)
library("randomForest")
library("randomForest")
model_rf <- randomForest(formula, data.train, mtry=13)
model_rf <- randomForest(formula, data.train)
pred_rf_train <- predict(model_rf, newdata=data.train)
pred_rf_test <- predict(model_rf, newdata=data.test)
pred_lasso_train <- predict(model_lasso,newdata=data.test, exact=TRUE)
pred_lasso_test <- predict(model_lasso, newdata=data.test, exact=TRUE)
options(width = 100)  # set output width
student.name <- "LI LIPING"  # put your name here
student.id <- 0320278  # put only the numeric digits of your NUS user id here
set.seed(student.id)
load("sales.rdata")  # load the data (make sure the .rdata file is in your working directory!)
ls(all.names=T)  # list all the objects in the data file
summary(data.train)
summary(data.test)
formula_1a <- as.formula(sales~weekend+holiday+prod_function+prod_regime+prod_listprice+discount+stockout)
formula_1b <- as.formula(sales~weekend+holiday+prod_function+prod_regime+prod_listprice+discount)
formula_1c <- as.formula(sales~weekend+holiday+prod_function+prod_listprice+discount)
data.train$log_sales <- log(1 + data.train$sales)
data.test$log_sales <- log(1 + data.test$sales)
formula <- as.formula(log_sales ~ weekend + holiday + prod_function + prod_regime + prod_listprice + discount + stockout)
model_2a <- lm(formula,data=data.train)
pred_lm_train <- predict(model_2a,data.train)
pred_lm_test <- predict(model_2a,data.test)
library("glmnetUtils")
# put your R code here inside the blocks
### The Lasso
# glmnet with alpha=1 means LASSO
model_lasso <- glmnet(formula,data.train,alpha=1, use.model.frame=TRUE)
plot(model_lasso, xvar="lambda", label=TRUE)
# CV for optimal lambda
set.seed(456)
lasso.cv <- cv.glmnet(formula,data.train,alpha=1, use.model.frame=TRUE)
plot(lasso.cv)
# optimal lambda
lasso.lam <- lasso.cv$lambda.min
log(lasso.lam)
points(log(lasso.lam), min(lasso.cv$cvm), cex=3)
#### alternatively, set optimal lambda to lambda.1se for a more parsimonious model ####
lasso.lam2 <- lasso.cv$lambda.1se
log(lasso.lam2)
min(lasso.cv$cvm) + lasso.cv$cvsd[which.min(lasso.cv$cvm)]
points(log(lasso.lam2), min(lasso.cv$cvm) + lasso.cv$cvsd[which.min(lasso.cv$cvm)], cex=3)
# plot optimal lambda
plot(lasso.cv$glmnet.fit, xvar="lambda", label = TRUE)
abline(v=log(lasso.lam), lty=2)
abline(v=log(lasso.lam2), lty=2)
# prediciton using optimal lambda
pred_lasso_train <- predict(lasso.cv, s=lasso.lam2, newdata=data.train, exact=TRUE)
pred_lasso_test <- predict(lasso.cv, s=lasso.lam2, newdata=data.test, exact=TRUE)
library("randomForest")
set.seed(12)  # there is randomness in the bootstrap part of bagging
# fit a bagging model (randomForest when mtry == p)
model_rf <- randomForest(formula, data.train)
# predict
pred_rf_train <- predict(model_rf, newdata=data.train)
pred_rf_test <- predict(model_rf, newdata=data.test)
pred_lasso_train <- predict(lasso.cv, s=lasso.lam, newdata=data.train, exact=TRUE)
pred_lasso_test <- predict(lasso.cv, s=lasso.lam, newdata=data.test, exact=TRUE)
??RMSE
library(Metrics)
RMSE_lm <- rmse(data.test$log_sales,pred_lm_test)
RMSE_lasso <- rmse(data.test$log_sales,pred_lasso_test)
RMSE_rf <- rmse(data.test$log_sales,pred_rf_test)
RMSE_lm
RMSE_lasso
RMSE_rf
rmse(data.train$log_sales,pred_rf_train)
